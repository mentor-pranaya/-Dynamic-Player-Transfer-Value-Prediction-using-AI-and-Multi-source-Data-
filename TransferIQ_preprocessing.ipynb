{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "base_path = Path(r\"C:\\Users\\Dharun Kumar\\OneDrive\\Desktop\\Infosys Springboard\")\n",
        "raw_path = base_path / \"final_data.csv\"\n",
        "df = pd.read_csv(raw_path)\n",
        "df_original = df.copy()\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
        "num_like = [\n",
        "\t\"height\",\"age\",\"appearance\",\"goals\",\"assists\",\"yellow_cards\",\"second_yellow_cards\",\"red_cards\",\n",
        "\t\"goals_conceded\",\"clean_sheets\",\"minutes_played\",\"days_injured\",\"games_injured\",\"award\",\n",
        "\t\"current_value\",\"highest_value\",\"position_encoded\",\"winger\"\n",
        "]\n",
        "for c in num_like:\n",
        "\tif c in df.columns:\n",
        "\t\tdf[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "str_like = [\"player\",\"team\",\"name\",\"position\"]\n",
        "for c in str_like:\n",
        "\tif c in df.columns:\n",
        "\t\tdf[c] = df[c].astype(\"string\").str.strip()\n",
        "\n",
        "basic_info = {\n",
        "\t\"shape\": df.shape,\n",
        "\t\"missing_perc\": df.isna().mean().sort_values(ascending=False).head(20),\n",
        "\t\"dtypes\": df.dtypes,\n",
        "\t\"describe_num\": df[num_like].describe()\n",
        "}\n",
        "basic_info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"minutes_played\"] = df[\"minutes_played\"].fillna(0)\n",
        "mp = df[\"minutes_played\"].replace(0, np.nan)\n",
        "per90 = {\n",
        "\t\"goals_p90\": df[\"goals\"] * 90 / mp,\n",
        "\t\"assists_p90\": df[\"assists\"] * 90 / mp,\n",
        "\t\"yc_p90\": df[\"yellow_cards\"] * 90 / mp,\n",
        "\t\"s2y_p90\": df[\"second_yellow_cards\"] * 90 / mp,\n",
        "\t\"rc_p90\": df[\"red_cards\"] * 90 / mp,\n",
        "\t\"ga_p90\": (df[\"goals\"] + df[\"assists\"]) * 90 / mp\n",
        "}\n",
        "for k,v in per90.items():\n",
        "\tdf[k] = v.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "app = df[\"appearance\"].replace(0, np.nan)\n",
        "avail = {\n",
        "\t\"injury_days_per_app\": df[\"days_injured\"] / app,\n",
        "\t\"injury_games_share\": df[\"games_injured\"] / (df[\"games_injured\"] + df[\"appearance\"]).replace(0, np.nan),\n",
        "\t\"availability_rate\": df[\"appearance\"] / (df[\"appearance\"] + df[\"games_injured\"]).replace(0, np.nan)\n",
        "}\n",
        "for k,v in avail.items():\n",
        "\tdf[k] = v.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "value_feats = {\n",
        "\t\"value_to_peak_ratio\": df[\"current_value\"] / df[\"highest_value\"].replace(0, np.nan),\n",
        "\t\"value_per_appearance\": df[\"current_value\"] / app,\n",
        "\t\"value_per_90\": df[\"current_value\"] / df[\"minutes_played\"].replace(0, np.nan) * 90\n",
        "}\n",
        "for k,v in value_feats.items():\n",
        "\tdf[k] = v.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "pos = df[\"position\"].fillna(\"\").str.lower()\n",
        "role_grp = np.select(\n",
        "\t[\n",
        "\t\tpos.str.contains(\"goalkeeper\"),\n",
        "\t\tpos.str.contains(\"defender\"),\n",
        "\t\tpos.str.contains(\"midfield\"),\n",
        "\t\tpos.str.contains(\"winger|forward|striker|centre-forward|rightwinger|leftwinger\")\n",
        "\t],\n",
        "\t[\"gk\",\"def\",\"mid\",\"att\"],\n",
        "\tdefault=\"other\"\n",
        ")\n",
        "df[\"role_group\"] = role_grp.astype(\"category\")\n",
        "\n",
        "df[\"is_winger\"] = df.get(\"winger\", pd.Series(index=df.index, dtype=float)).fillna(0).astype(int)\n",
        "\n",
        "career_stage = pd.cut(df[\"age\"], bins=[0,20,24,28,32,100], labels=[\"teen\",\"u24\",\"peak\",\"u32\",\"veteran\"], include_lowest=True)\n",
        "df[\"career_stage\"] = career_stage.astype(\"category\")\n",
        "\n",
        "df[\"discipline_score\"] = df[[\"yellow_cards\",\"second_yellow_cards\",\"red_cards\"]].fillna(0).dot([1,2,5]) / (app.replace(0, np.nan))\n",
        "df[\"discipline_score\"] = df[\"discipline_score\"].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "num_new = [\n",
        "\t\"goals_p90\",\"assists_p90\",\"yc_p90\",\"s2y_p90\",\"rc_p90\",\"ga_p90\",\n",
        "\t\"injury_days_per_app\",\"injury_games_share\",\"availability_rate\",\n",
        "\t\"value_to_peak_ratio\",\"value_per_appearance\",\"value_per_90\",\"discipline_score\"\n",
        "]\n",
        "cat_new = [\"role_group\",\"career_stage\",\"team\",\"position\"]\n",
        "\n",
        "df_engineered = df.copy()\n",
        "{\n",
        "\t\"engineered_numeric_preview\": df_engineered[num_new].head(3),\n",
        "\t\"engineered_categoricals_preview\": df_engineered[cat_new].head(3)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_dir = base_path / \"processed\"\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "engineered_path = out_dir / \"engineered_dataset.csv\"\n",
        "df_engineered.to_csv(engineered_path, index=False)\n",
        "{\n",
        "\t\"saved_path\": str(engineered_path),\n",
        "\t\"rows\": len(df_engineered),\n",
        "\t\"cols\": len(df_engineered.columns),\n",
        "\t\"numeric_features\": [\n",
        "\t\t\"goals_p90\",\"assists_p90\",\"yc_p90\",\"s2y_p90\",\"rc_p90\",\"ga_p90\",\n",
        "\t\t\"injury_days_per_app\",\"injury_games_share\",\"availability_rate\",\n",
        "\t\t\"value_to_peak_ratio\",\"value_per_appearance\",\"value_per_90\",\"discipline_score\"\n",
        "\t],\n",
        "\t\"categorical_features\": [\"role_group\",\"career_stage\",\"team\",\"position\",\"is_winger\"]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, subprocess\n",
        "try:\n",
        "\timport tensorflow as tf\n",
        "except Exception:\n",
        "\tsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"tensorflow-cpu==2.15.0\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\timport tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "np.random.seed(42)\n",
        "engineered_path = Path(base_path) / \"processed\" / \"engineered_dataset.csv\"\n",
        "dfe = pd.read_csv(engineered_path)\n",
        "features_dyn = [\n",
        "\t\"ga_p90\",\"availability_rate\",\"injury_games_share\",\"discipline_score\"\n",
        "]\n",
        "value_col = \"current_value\"\n",
        "T_hist = 12\n",
        "H_forecast = 3\n",
        "\n",
        "vals = dfe[value_col].fillna(dfe[value_col].median()).to_numpy()\n",
        "feat_mat = dfe[features_dyn].fillna(dfe[features_dyn].median()).to_numpy()\n",
        "alpha = 0.6 + 0.2 * (feat_mat[:,0] - np.nanmin(feat_mat[:,0])) / (np.nanmax(feat_mat[:,0]) - np.nanmin(feat_mat[:,0]) + 1e-9)\n",
        "trend = 0.02 * (feat_mat[:,0] - feat_mat[:,0].mean()) - 0.03 * (feat_mat[:,2] - feat_mat[:,2].mean())\n",
        "noise_scale = 0.05 + 0.1 * (feat_mat[:,2] - np.nanmin(feat_mat[:,2])) / (np.nanmax(feat_mat[:,2]) - np.nanmin(feat_mat[:,2]) + 1e-9)\n",
        "\n",
        "hist = np.zeros((len(vals), T_hist))\n",
        "for i in range(len(vals)):\n",
        "\tseries = np.zeros(T_hist)\n",
        "\tlevel = max(vals[i], 1.0)\n",
        "\tfor t in range(T_hist-1, -1, -1):\n",
        "\t\teps = np.random.normal(0, noise_scale[i] * level)\n",
        "\t\tlevel = alpha[i] * level + (1 - alpha[i]) * vals[i] * (1 + trend[i]) + eps\n",
        "\t\tseries[t] = max(level, 0.0)\n",
        "\thist[i] = series\n",
        "\n",
        "dyn_seq = np.zeros((len(vals), T_hist, len(features_dyn)))\n",
        "for j in range(len(features_dyn)):\n",
        "\tbase = feat_mat[:, j:j+1]\n",
        "\tnoise = np.random.normal(0, 0.02, size=(len(vals), T_hist))\n",
        "\tdyn = np.repeat(base, T_hist, axis=1) + noise\n",
        "\tdyn = np.clip(dyn, np.percentile(dyn, 0.5), np.percentile(dyn, 99.5))\n",
        "\tdyn_seq[:,:,j] = dyn\n",
        "\n",
        "y_targets = np.zeros((len(vals), H_forecast))\n",
        "for i in range(len(vals)):\n",
        "\tfuture = []\n",
        "\tlevel = hist[i,-1]\n",
        "\tfor h in range(H_forecast):\n",
        "\t\teps = np.random.normal(0, noise_scale[i] * level)\n",
        "\t\tlevel = alpha[i] * level + (1 - alpha[i]) * vals[i] * (1 + trend[i]) + eps\n",
        "\t\tfuture.append(max(level, 0.0))\n",
        "\ty_targets[i] = future\n",
        "\n",
        "X_univariate = hist.reshape(len(vals), T_hist, 1)\n",
        "X_multivariate = np.concatenate([hist.reshape(len(vals), T_hist, 1), dyn_seq], axis=2)\n",
        "\n",
        "idx = np.arange(len(vals))\n",
        "np.random.shuffle(idx)\n",
        "train_sz = int(0.8 * len(idx))\n",
        "train_idx, val_idx = idx[:train_sz], idx[train_sz:]\n",
        "\n",
        "X_uni_tr, X_uni_va = X_univariate[train_idx], X_univariate[val_idx]\n",
        "X_multi_tr, X_multi_va = X_multivariate[train_idx], X_multivariate[val_idx]\n",
        "y_tr_1, y_va_1 = y_targets[train_idx, 0], y_targets[val_idx, 0]\n",
        "y_tr_seq, y_va_seq = y_targets[train_idx], y_targets[val_idx]\n",
        "\n",
        "scale_val = np.median(dfe[\"current_value\"].clip(lower=1.0))\n",
        "X_uni_tr = X_uni_tr / scale_val\n",
        "X_uni_va = X_uni_va / scale_val\n",
        "X_multi_tr = X_multi_tr.copy()\n",
        "X_multi_va = X_multi_va.copy()\n",
        "X_multi_tr[:,:,0] = X_multi_tr[:,:,0] / scale_val\n",
        "X_multi_va[:,:,0] = X_multi_va[:,:,0] / scale_val\n",
        "y_tr_1 = y_tr_1 / scale_val\n",
        "y_va_1 = y_va_1 / scale_val\n",
        "y_tr_seq = y_tr_seq / scale_val\n",
        "y_va_seq = y_va_seq / scale_val\n",
        "\n",
        "X_uni_tr.shape, X_multi_tr.shape, y_tr_1.shape, y_tr_seq.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "uni_model = keras.Sequential([\n",
        "\tlayers.Input(shape=(T_hist,1)),\n",
        "\tlayers.LSTM(64, return_sequences=False),\n",
        "\tlayers.Dense(32, activation=\"relu\"),\n",
        "\tlayers.Dense(1)\n",
        "])\n",
        "uni_model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
        "h_uni = uni_model.fit(X_uni_tr, y_tr_1, validation_data=(X_uni_va, y_va_1), epochs=25, batch_size=64, verbose=0)\n",
        "\n",
        "va_pred_uni = uni_model.predict(X_uni_va, verbose=0).ravel()\n",
        "mae_uni = np.mean(np.abs(va_pred_uni - y_va_1))\n",
        "rmse_uni = np.sqrt(np.mean((va_pred_uni - y_va_1)**2))\n",
        "r2_uni = 1 - np.sum((va_pred_uni - y_va_1)**2) / np.sum((y_va_1 - y_va_1.mean())**2 + 1e-9)\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(h_uni.history[\"loss\"], label=\"train\")\n",
        "plt.plot(h_uni.history[\"val_loss\"], label=\"val\")\n",
        "plt.title(\"Univariate LSTM Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "mae_uni, rmse_uni, r2_uni\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "multi_model = keras.Sequential([\n",
        "\tlayers.Input(shape=(T_hist, X_multi_tr.shape[-1])),\n",
        "\tlayers.LSTM(64, return_sequences=False),\n",
        "\tlayers.Dense(64, activation=\"relu\"),\n",
        "\tlayers.Dense(1)\n",
        "])\n",
        "multi_model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
        "h_multi = multi_model.fit(X_multi_tr, y_tr_1, validation_data=(X_multi_va, y_va_1), epochs=25, batch_size=64, verbose=0)\n",
        "\n",
        "va_pred_multi = multi_model.predict(X_multi_va, verbose=0).ravel()\n",
        "mae_multi = np.mean(np.abs(va_pred_multi - y_va_1))\n",
        "rmse_multi = np.sqrt(np.mean((va_pred_multi - y_va_1)**2))\n",
        "r2_multi = 1 - np.sum((va_pred_multi - y_va_1)**2) / np.sum((y_va_1 - y_va_1.mean())**2 + 1e-9)\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(h_multi.history[\"loss\"], label=\"train\")\n",
        "plt.plot(h_multi.history[\"val_loss\"], label=\"val\")\n",
        "plt.title(\"Multivariate LSTM Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "mae_multi, rmse_multi, r2_multi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "enc_in = layers.Input(shape=(T_hist, X_multi_tr.shape[-1]))\n",
        "enc_l1 = layers.LSTM(64, return_sequences=False)(enc_in)\n",
        "rep = layers.RepeatVector(H_forecast)(enc_l1)\n",
        "dec_l1 = layers.LSTM(64, return_sequences=True)(rep)\n",
        "out = layers.TimeDistributed(layers.Dense(1))(dec_l1)\n",
        "encdec_model = keras.Model(enc_in, out)\n",
        "encdec_model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
        "\n",
        "h_enc = encdec_model.fit(X_multi_tr, y_tr_seq.reshape(-1, H_forecast, 1),\n",
        "\tvalidation_data=(X_multi_va, y_va_seq.reshape(-1, H_forecast, 1)),\n",
        "\tepochs=30, batch_size=64, verbose=0)\n",
        "\n",
        "va_pred_seq = encdec_model.predict(X_multi_va, verbose=0).squeeze(-1)\n",
        "mae_seq = np.mean(np.abs(va_pred_seq - y_va_seq))\n",
        "rmse_seq = np.sqrt(np.mean((va_pred_seq - y_va_seq)**2))\n",
        "r2_seq = 1 - np.sum((va_pred_seq - y_va_seq)**2) / np.sum((y_va_seq - y_va_seq.mean())**2 + 1e-9)\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(h_enc.history[\"loss\"], label=\"train\")\n",
        "plt.plot(h_enc.history[\"val_loss\"], label=\"val\")\n",
        "plt.title(\"Encoder-Decoder LSTM Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "mae_seq, rmse_seq, r2_seq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_dir = base_path / \"models\"\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "uni_path = models_dir / \"univariate_lstm.keras\"\n",
        "multi_path = models_dir / \"multivariate_lstm.keras\"\n",
        "encdec_path = models_dir / \"encdec_lstm.keras\"\n",
        "\n",
        "uni_model.save(uni_path)\n",
        "multi_model.save(multi_path)\n",
        "encdec_model.save(encdec_path)\n",
        "\n",
        "metrics = pd.DataFrame({\n",
        "\t\"model\": [\"univariate\",\"multivariate\",\"encdec_seq\"],\n",
        "\t\"mae\": [mae_uni, mae_multi, mae_seq],\n",
        "\t\"rmse\": [rmse_uni, rmse_multi, rmse_seq],\n",
        "\t\"r2\": [r2_uni, r2_multi, r2_seq]\n",
        "})\n",
        "metrics_path = models_dir / \"metrics.csv\"\n",
        "metrics.to_csv(metrics_path, index=False)\n",
        "metrics, str(metrics_path)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
