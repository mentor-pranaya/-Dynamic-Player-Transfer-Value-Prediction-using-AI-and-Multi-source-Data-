{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPl2l2JWcgP8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load datasets\n",
        "market_df = pd.read_csv(\"/content/Feature Engineering/player_valuations_featured.csv\")\n",
        "injury_df = pd.read_csv(\"/content/Feature Engineering/Injury_data.csv\")\n",
        "sentiment_df = pd.read_csv(\"/content/Sentiment_Analysis/final_featured_dataset.csv\")\n",
        "\n",
        "# Convert player IDs to string for consistency\n",
        "market_df['player_id'] = market_df['player_id'].astype(str)\n",
        "injury_df['p_id2'] = injury_df['p_id2'].astype(str)\n",
        "sentiment_df['player_id'] = sentiment_df['player_id'].astype(str)\n",
        "performance_df['player.name'] = performance_df['player.name'].astype(str)  # if needed\n",
        "\n",
        "# Convert date columns to datetime\n",
        "market_df['date'] = pd.to_datetime(market_df['date'])\n",
        "sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
        "# If injury has start_year only, create approximate date\n",
        "injury_df['start_year'] = pd.to_datetime(injury_df['start_year'], format='%Y', errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61RBVYpydETP"
      },
      "outputs": [],
      "source": [
        "merged_df = market_df.merge(\n",
        "    injury_df, left_on='player_id', right_on='p_id2', how='left', suffixes=('', '_inj')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9FY4zThdGut"
      },
      "outputs": [],
      "source": [
        "merged_df = merged_df.merge(\n",
        "    sentiment_df, on=['player_id', 'date'], how='left', suffixes=('', '_sent')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgCaxHM6dZ4g",
        "outputId": "ea6553f0-03a9-417b-acf6-4500c51ad214"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2660247286.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  performance_df['timestamp'] = pd.to_datetime(performance_df['timestamp'], errors='coerce')\n",
            "/tmp/ipython-input-2660247286.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  performance_df['date'] = performance_df['timestamp'].dt.date\n"
          ]
        }
      ],
      "source": [
        "# Convert timestamp to datetime\n",
        "performance_df['timestamp'] = pd.to_datetime(performance_df['timestamp'], errors='coerce')\n",
        "\n",
        "# Extract date only\n",
        "performance_df['date'] = performance_df['timestamp'].dt.date\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFIE8ls6eRBH",
        "outputId": "827c7070-26cb-403d-bf10-f61e45b2f7a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2688359054.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  performance_df['goals'] = performance_df['type.name'].apply(lambda x: 1 if x == 'Goal' else 0)\n",
            "/tmp/ipython-input-2688359054.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  performance_df['assists'] = performance_df['pass.goal_assist'].apply(lambda x: 1 if x != 0 else 0)\n",
            "/tmp/ipython-input-2688359054.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  performance_df['yellow_cards'] = performance_df['bad_behaviour.card.name'].apply(lambda x: 1 if x=='Yellow Card' else 0)\n",
            "/tmp/ipython-input-2688359054.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  performance_df['red_cards'] = performance_df['bad_behaviour.card.name'].apply(lambda x: 1 if x=='Red Card' else 0)\n",
            "/tmp/ipython-input-2688359054.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  performance_df['minutes_played'] = 1  # or approximate by event counts per match\n"
          ]
        }
      ],
      "source": [
        "# Create goals column\n",
        "performance_df['goals'] = performance_df['type.name'].apply(lambda x: 1 if x == 'Goal' else 0)\n",
        "\n",
        "# Create assists column (if 'pass.goal_assist' exists, use it)\n",
        "performance_df['assists'] = performance_df['pass.goal_assist'].apply(lambda x: 1 if x != 0 else 0)\n",
        "\n",
        "# Create yellow/red cards columns\n",
        "performance_df['yellow_cards'] = performance_df['bad_behaviour.card.name'].apply(lambda x: 1 if x=='Yellow Card' else 0)\n",
        "performance_df['red_cards'] = performance_df['bad_behaviour.card.name'].apply(lambda x: 1 if x=='Red Card' else 0)\n",
        "\n",
        "# Create minutes played approximation per event (if minute exists)\n",
        "performance_df['minutes_played'] = 1  # or approximate by event counts per match\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3A38RFrefbP"
      },
      "outputs": [],
      "source": [
        "performance_df['timestamp'] = pd.to_datetime(performance_df['timestamp'], errors='coerce')\n",
        "performance_df['date'] = performance_df['timestamp'].dt.date\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvgLIiy9ehBl"
      },
      "outputs": [],
      "source": [
        "agg_funcs = {\n",
        "    'goals': 'sum',\n",
        "    'assists': 'sum',\n",
        "    'minutes_played': 'sum',\n",
        "    'yellow_cards': 'sum',\n",
        "    'red_cards': 'sum'\n",
        "}\n",
        "\n",
        "perf_agg = performance_df.groupby(['player.name', 'date']).agg(agg_funcs).reset_index()\n",
        "perf_agg.rename(columns={'player.name': 'player_id'}, inplace=True)\n",
        "perf_agg['player_id'] = perf_agg['player_id'].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJuLxIMidKbb"
      },
      "outputs": [],
      "source": [
        "# Ensure IDs and dates are consistent\n",
        "market_df['player_id'] = market_df['player_id'].astype(str)\n",
        "sentiment_df['player_id'] = sentiment_df['player_id'].astype(str)\n",
        "injury_df['p_id2'] = injury_df['p_id2'].astype(str)\n",
        "perf_agg['player_id'] = perf_agg['player_id'].astype(str)\n",
        "\n",
        "market_df['date'] = pd.to_datetime(market_df['date'])\n",
        "sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
        "perf_agg['date'] = pd.to_datetime(perf_agg['date'])\n",
        "# Injury dataset might have start_year; approximate date\n",
        "injury_df['start_year'] = pd.to_datetime(injury_df['start_year'], format='%Y', errors='coerce')\n",
        "\n",
        "# Merge market + injury\n",
        "merged_df = market_df.merge(\n",
        "    injury_df, left_on='player_id', right_on='p_id2', how='left', suffixes=('', '_inj')\n",
        ")\n",
        "\n",
        "# Merge with sentiment\n",
        "merged_df = merged_df.merge(\n",
        "    sentiment_df, on=['player_id', 'date'], how='left', suffixes=('', '_sent')\n",
        ")\n",
        "\n",
        "# Merge with performance\n",
        "merged_df = merged_df.merge(\n",
        "    perf_agg, on=['player_id', 'date'], how='left', suffixes=('', '_perf')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_EBr8K4ewCy"
      },
      "outputs": [],
      "source": [
        "# Fill numeric columns with 0\n",
        "num_cols = merged_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "merged_df[num_cols] = merged_df[num_cols].fillna(0)\n",
        "\n",
        "# Fill categorical/object columns with 'unknown'\n",
        "cat_cols = merged_df.select_dtypes(include=['object']).columns\n",
        "merged_df[cat_cols] = merged_df[cat_cols].fillna('unknown')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lQa4IZbe1BR"
      },
      "outputs": [],
      "source": [
        "# Example features combining market, injury, sentiment, and performance\n",
        "features = [\n",
        "    'player_age', 'goals', 'assists', 'minutes_played', 'yellow_cards', 'red_cards',\n",
        "    'total_transfers', 'total_market_value', 'season_days_injured', 'cumulative_days_injured',\n",
        "    'minutes_per_game_prev_seasons', 'avg_days_injured_prev_seasons',\n",
        "    'avg_games_per_season_prev_seasons', 'bmi', 'significant_injury_prev_season',\n",
        "    'compound_mean', 'compound_std', 'compound_min', 'compound_max',\n",
        "    'polarity_mean', 'polarity_std'\n",
        "]\n",
        "\n",
        "target = ['market_value_in_eur']\n",
        "\n",
        "X = merged_df[features].values\n",
        "y = merged_df[target].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGgbrG2Ve2Tm"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b03SIlVte7XB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(X, y, n_input, n_output):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - n_input - n_output + 1):\n",
        "        X_seq.append(X[i:i+n_input])\n",
        "        y_seq.append(y[i+n_input:i+n_input+n_output])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "n_input = 10  # last 10 windows\n",
        "n_output = 5  # predict next 5 windows\n",
        "\n",
        "X_seq, y_seq = create_sequences(X_scaled, y_scaled, n_input, n_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "hzUOP_-Ve-rP",
        "outputId": "25c2dae5-affa-4781-df1d-184cfd4272cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">76,800</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
              "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m21\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │     \u001b[38;5;34m76,800\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │    \u001b[38;5;34m131,584\u001b[0m │ repeat_vector[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
              "│                     │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │        \u001b[38;5;34m129\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">208,513</span> (814.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m208,513\u001b[0m (814.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">208,513</span> (814.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m208,513\u001b[0m (814.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
        "\n",
        "n_features = X_seq.shape[2]\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(n_input, n_features))\n",
        "encoder_lstm = LSTM(128, activation='relu', return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = RepeatVector(n_output)(state_h)\n",
        "decoder_lstm = LSTM(128, activation='relu', return_sequences=True)\n",
        "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = TimeDistributed(Dense(1))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model(encoder_inputs, decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxJ56qnYf_S8",
        "outputId": "7a49978f-ba71-4b5d-caa3-e5f073e72bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3104/3104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 71ms/step - loss: 9.0100e-04 - val_loss: 0.0018\n",
            "Epoch 2/50\n",
            "\u001b[1m3104/3104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 64ms/step - loss: 8.8110e-04 - val_loss: 0.0018\n",
            "Epoch 3/50\n",
            "\u001b[1m3104/3104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 62ms/step - loss: 8.7567e-04 - val_loss: 0.0018\n",
            "Epoch 4/50\n",
            "\u001b[1m3104/3104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 62ms/step - loss: 8.6627e-04 - val_loss: 0.0018\n",
            "Epoch 5/50\n",
            "\u001b[1m3104/3104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 62ms/step - loss: 8.6108e-04 - val_loss: 0.0018\n",
            "Epoch 6/50\n",
            "\u001b[1m3104/3104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 64ms/step - loss: 8.5954e-04 - val_loss: 0.0020\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_seq, y_seq,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
