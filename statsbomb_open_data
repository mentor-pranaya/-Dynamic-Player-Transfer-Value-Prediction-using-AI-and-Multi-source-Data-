'''
import pandas as pd
from statsbombpy import sb
import os


# Get the complete list of all available competitions and seasons
df_all_data = pd.DataFrame(sb.competitions())


#File path in which i want my data to be stored
id_file_path = "/Users/nishantgupta/Downloads/Internship Dataset/id_data(StatsBomb).csv"
df_all_data.to_csv(id_file_path , index=False)

print(f"Successfully saved match data to {id_file_path}")



# 1. Get a list of all available competitions to find the ID you need
competitions = sb.competitions()
print("Available Competitions:")
print(competitions[['competition_id', 'season_id', 'competition_name', 'season_name']])

# The FIFA World Cup 2022 (competition_id=43, season_id=106)

# 2. Get all matches for that competition
# The library fetches and combines the data for you.
world_cup_matches = sb.matches(competition_id=43, season_id=106)

# 3. Load it into a pandas DataFrame for analysis
df_matches = pd.DataFrame(world_cup_matches)

print("\nAll Matches from FIFA World Cup 2022:")
print(df_matches[['match_id', 'home_team', 'away_team', 'match_date']].head())

# Each match has a unique match_id. We'll pick the first match from our matches dataset.
match_id = world_cup_matches.loc[0, "match_id"]  # Access the first match_id
events = sb.events(match_id=match_id)  # Fetch all events (passes, shots, fouls, etc.) for that match

# Display first few rows of events data
print("\nEvents dataset sample:")
print(events.head())

# Save raw events dataset for this match (deliverable for Week 1)
events.to_csv(f"match_{match_id}_events.csv", index=False)


# Exploring the dataset
print("\n Events Data Info: ")
print(events.info())


print("\n Missing values in each coloumns: ")
print(events.isnull().sum())

counting_events = events["type"].value_counts()
print("\n Event Type counts: ")
print(counting_events)


# Player performance - pass taken
passes = events[events["type"] == "Pass"]
print("\nPasses Data Sample (Player, Team, Outcome):")
print(passes[["player" , "team" , "pass_outcome"]].head())

'''


'''
import pandas as pd
from statsbombpy import sb
import os
import time
import matplotlib.pyplot as plt
import seaborn as sns

# -----------------------------------------
# STEP 1: AUTOMATED DATA COLLECTION FOR ALL MATCHES
# -----------------------------------------

# --- Setup: Create a folder to save the event files ---
events_folder = "data/world_cup_events"
if not os.path.exists(events_folder):
    os.makedirs(events_folder)

# --- Get all matches for the competition ---
world_cup_matches = pd.DataFrame(sb.matches(competition_id=43, season_id=106))
print(f"Found {len(world_cup_matches)} matches for the competition.")

# --- Loop through each match to get its event data ---
for index, row in world_cup_matches.iterrows():
    match_id = row['match_id']
    file_path = f"{events_folder}/match_{match_id}_events.csv"

    # Check if the file already exists before downloading
    if not os.path.exists(file_path):
        print(f"Fetching event data for match_id: {match_id}...")
        try:
            events = pd.DataFrame(sb.events(match_id=match_id))
            events.to_csv(file_path, index=False)
            print(f"   -> Saved data to {file_path}")
        except Exception as e:
            print(f"   -> Could not fetch data for match {match_id}. Error: {e}")
        time.sleep(1)
    else:
        print(f"Skipping match_id: {match_id} (file already exists).")

print("\nProcess complete. All available event data has been downloaded.")

# -----------------------------------------
# STEP 2: EDA ON THE FIRST MATCH
# -----------------------------------------
print("\n--- Starting EDA on the first match ---")

# Get the ID of the first match to load its corresponding file
first_match_id = world_cup_matches.loc[0, "match_id"]
first_match_file = f"{events_folder}/match_{first_match_id}_events.csv"

# Load the event data for the first match from the CSV file
events = pd.read_csv(first_match_file)

# 2.1: View general information about the dataset
print("\nEvents Data Info:")
events.info()

# 2.2: Check for missing values
print("\nMissing values in each column:")
print(events.isnull().sum())

# 2.3: Analyze event types
event_counts = events["type"].value_counts()
print("\nEvent Type Counts:")
print(event_counts.head())

# Plot top 10 event types
plt.figure(figsize=(10, 5))
sns.barplot(x=event_counts.index[:10], y=event_counts.values[:10])
plt.title(f"Top 10 Event Types in Match {first_match_id}")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.show()

# 2.4: Focus on Player Performance - Shots Taken
shots = events[events["type"] == "Shot"]
print("\nShots Data Sample (Player, Team, Outcome):")
print(shots[["player", "team", "shot_outcome"]].head())

# Count number of shots per player
shots_per_player = shots["player"].value_counts().head(10)

# Visualize top 10 players by shots
plt.figure(figsize=(8, 5))
sns.barplot(x=shots_per_player.index, y=shots_per_player.values)
plt.title(f"Top 10 Players by Shots in Match {first_match_id}")
plt.ylabel("Shots")
plt.xticks(rotation=45)
plt.show()
'''


# extra
'''
# File: add_player_ids.py
# This script adds a 'player_id' column to the existing performance summary CSV.

import pandas as pd
import os
import json
from glob import glob

# --- 1. SETUP PATHS ---
# !!! IMPORTANT: CHANGE THIS PATH TO POINT TO YOUR STATSBOMB 'open-data' FOLDER !!!
BASE_PATH = r"/Users/nishantgupta/Desktop/Internship Project/StatsBomb open data/data"
PROCESSED_DATA_FOLDER = r"/Users/nishantgupta/Desktop/Internship Project"
PLAYER_SUMMARY_FILE = os.path.join(PROCESSED_DATA_FOLDER, "complete_statsbomb_data.csv")

# Path to the raw lineup data
PATH_LINEUPS = os.path.join(BASE_PATH, "lineups")

# --- 2. CHECK IF THE SUMMARY FILE EXISTS ---
if not os.path.exists(PLAYER_SUMMARY_FILE):
    print(f"Error: The file '{PLAYER_SUMMARY_FILE}' was not found.")
    print("Please make sure you have run the main processing script first.")
    exit()

# --- 3. CREATE A PLAYER NAME TO ID MAPPING ---
print("Processing lineup files to create a player name-to-ID map...")
player_name_to_id_map = {}
# Loop through all lineup files
for file in glob(os.path.join(PATH_LINEUPS, "*.json")):
    with open(file, "r", encoding="utf-8") as f:
        lineups_data = json.load(f)
        for team in lineups_data:
            for player in team["lineup"]:
                player_id = player.get("player_id")
                player_name = player.get("player_name")
                # Store the mapping, it will handle duplicates automatically
                if player_id and player_name:
                    player_name_to_id_map[player_name] = player_id

print(f"Created a map for {len(player_name_to_id_map)} unique player names.")

# --- 4. LOAD, UPDATE, AND SAVE THE CSV ---
print(f"Loading data from '{PLAYER_SUMMARY_FILE}'...")
df = pd.read_csv(PLAYER_SUMMARY_FILE)

# Create the new 'player_id' column by mapping the 'player_name' column
df['player_id'] = df['player_name'].map(player_name_to_id_map)

# Reorder columns to have 'player_id' near the front
cols = ['player_id'] + [col for col in df.columns if col != 'player_id']
df = df[cols]

# Save the updated DataFrame back to the same file
df.to_csv(PLAYER_SUMMARY_FILE, index=False)

print("\n" + "="*50)
print(f"Successfully updated '{PLAYER_SUMMARY_FILE}' with a 'player_id' column.")
print("="*50)
print("\n--- Updated Data Preview ---")
print(df.head())
'''


#Data Cleaning and feature engineering
import pandas as pd
import numpy as np

def clean_and_engineer_features(input_file):
    """
    This script performs data cleaning and feature engineering on the aggregated
    StatsBomb player performance data.
    """
    try:
        print(f"Reading data from '{input_file}'...")
        df = pd.read_csv(input_file)
    except FileNotFoundError:
        print(f"Error: The file '{input_file}' was not found.")
        return

    # --- 1. DATA CLEANING ---
    print("\n--- Starting Data Cleaning ---")
    
    # a) Check for and handle missing values
    # For this dataset, a missing value in a performance metric likely means zero.
    numeric_cols = ['goals', 'assists', 'shots', 'total_xG', 'matches_played']
    for col in numeric_cols:
        df[col] = df[col].fillna(0)
    print("Handled missing values by filling with 0.")

    # b) Correct data types
    df['player_id'] = df['player_id'].astype(int)
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col])
    print("Corrected data types for key columns.")

    # --- 2. BASIC FEATURE ENGINEERING ---
    print("\n--- Starting Basic Feature Engineering ---")

    # a) Calculate per-match statistics for better comparison across players
    # Using np.divide to handle division by zero gracefully (results in NaN)
    df['goals_per_match'] = np.divide(df['goals'], df['matches_played'])
    df['assists_per_match'] = np.divide(df['assists'], df['matches_played'])
    df['shots_per_match'] = np.divide(df['shots'], df['matches_played'])
    df['xG_per_match'] = np.divide(df['total_xG'], df['matches_played'])
    
    # b) Calculate efficiency metrics
    df['goal_conversion_rate'] = np.divide(df['goals'], df['shots'])
    
    # c) Calculate performance relative to expectation (xG)
    # This shows if a player is overperforming or underperforming their chances.
    df['xG_performance'] = df['goals'] - df['total_xG']

    # Fill any potential NaN values from division by zero with 0
    df.fillna(0, inplace=True)
    print("Created new features: per-match stats, conversion rate, and xG performance.")

    # --- 3. ADVANCED FEATURE ENGINEERING (PERFORMANCE TRENDS) ---
    print("\n--- Starting Advanced Feature Engineering ---")

    # To calculate trends, we need to compare a player's stats to their previous season.
    # a) First, sort the data by player and season to ensure correct ordering.
    # The 'season_name' needs to be sorted chronologically (e.g., '2015/2016' before '2016/2017')
    df_sorted = df.sort_values(by=['player_name', 'season_name'])

    # b) Group by player and get the stats from the previous season using .shift()
    shifted_cols = {}
    for col in ['goals', 'assists', 'shots', 'total_xG', 'matches_played']:
        shifted_cols[f'prev_season_{col}'] = df_sorted.groupby('player_name')[col].shift(1)
    
    df_trends = pd.concat([df_sorted, pd.DataFrame(shifted_cols)], axis=1)

    # c) Calculate year-over-year (YoY) change
    # This captures a player's performance trajectory (improving, declining, or stable)
    df_trends['goals_yoy_change'] = df_trends['goals'] - df_trends['prev_season_goals']
    df_trends['assists_yoy_change'] = df_trends['assists'] - df_trends['prev_season_assists']

    # Fill NaN values for the first season of each player with 0
    df_trends.fillna(0, inplace=True)
    print("Created new features for year-over-year performance trends.")
    
    # --- 4. SAVE THE FINAL, ENRICHED DATASET ---
    output_file = "player_performance_engineered.csv"
    df_trends.to_csv(output_file, index=False)

    print("\n" + "="*50)
    print(f"Data cleaning and feature engineering complete.")
    print(f"Final dataset saved to '{output_file}'")
    print("="*50)
    
    print("\n--- Final Data Preview (with new features) ---")
    print(df_trends.head())


if __name__ == "__main__":
    # The file you uploaded from the previous step
    statsbomb_summary_file = "/Users/nishantgupta/Desktop/Internship Project/complete_statsbomb_data.csv"
    clean_and_engineer_features(statsbomb_summary_file)
