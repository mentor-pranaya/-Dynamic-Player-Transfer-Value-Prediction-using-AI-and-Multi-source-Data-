{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f4659a",
   "metadata": {},
   "source": [
    "#Multivariate LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda5fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d66f12",
   "metadata": {},
   "source": [
    "How to save and reload scaler to always use the same scale during training, validation, and prediction. This keeps the model’s outputs consistent and comparable across runs.\n",
    "\n",
    "1️ Fit and Save the Global Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaca450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "features_cols = [\"market_value\",\"total_injuries\",\"sentiment_mean\",\"avg_cards_per_match\"]\n",
    "\n",
    "# Fit once on your entire dataset\n",
    "global_scaler = MinMaxScaler()\n",
    "global_scaler.fit(df[features_cols].fillna(0).values)\n",
    "\n",
    "# Save to disk\n",
    "joblib.dump(global_scaler, \"global_scaler.pkl\")\n",
    "print(\"✅ Scaler saved to global_scaler.pkl\")\n",
    "\n",
    "#This writes a binary file you can load later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329e274",
   "metadata": {},
   "source": [
    "2️ Load the Scaler Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74478965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the same scaler back\n",
    "global_scaler = joblib.load(\"global_scaler.pkl\")\n",
    "print(\"✅ Scaler loaded. Feature mins:\", global_scaler.data_min_)\n",
    "\n",
    "#This ensures the exact same min/max values are used for transforming new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf7bbe",
   "metadata": {},
   "source": [
    "3️ Use During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713202a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside the loop:\n",
    "features = group[features_cols].fillna(0).values\n",
    "scaled = global_scaler.transform(features)  # not fit_transform!\n",
    "\n",
    "#Because we already fit it globally, we only call `.transform()` on each new subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c2aba",
   "metadata": {},
   "source": [
    "4️ Use During Inference / Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7035bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to predict for one player:\n",
    "features = player_df[features_cols].fillna(0).values\n",
    "scaled = global_scaler.transform(features)\n",
    "\n",
    "Xp, yp = make_multivariate_multistep(scaled, n_steps, n_future)\n",
    "pred_scaled = model.predict(Xp)\n",
    "\n",
    "# Inverse transform only the target column (market_value):\n",
    "dummy = np.zeros((pred_scaled.shape[0], len(features_cols)))\n",
    "\n",
    "for step in range(n_future):\n",
    "    dummy[:,0] = pred_scaled[:,step]\n",
    "    inv = global_scaler.inverse_transform(dummy)\n",
    "    y_pred_original = inv[:,0]  # this is in actual market value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15afe54",
   "metadata": {},
   "source": [
    "All training, validation, and prediction are on one consistent scale.\n",
    "We can stop worrying about each run giving different min/max.\n",
    "We can deploy your model and apply the same scaler on live data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
