# Day 1 Progress Report – Abhay Raj  
**Date:** 18/08/2025  

## 1. Perfect Data Illusion
- Mentor discussed the concept of **Perfect Data Illusion**.  
- It refers to when data looks "too clean" or "too perfect" compared to real-world datasets.  
- Real-world data usually has missing values, noise, and outliers.  
- Having perfectly clean data is a **bad sign** because it may indicate:  
  - Over-processed data (important signals lost).  
  - Possible fabrication or manipulation.  
  - Lack of variability, which makes models fail to generalize.  

## 2. GitHub Setup
- Joined the GitHub repository using the mentor’s invitation.  
- Created my personal branch named `abhay_raj`.  
- Added a text file for daily updates.  

## 3. Data Collection Exploration
- Checked StatsBomb Open Data for player performance datasets.  
- Looked into Transfermarkt for player market value data.  
- Searched initial sources for injury-related data.  

## 4. Challenges
- Extracting structured data from Transfermarkt still needs more work.  
- Injury data sources are not finalized yet.  

## 5. Tomorrow’s Question
- Mentor provided a discussion point for tomorrow:  
  **“What is huge data in machine learning?”**  
  - Does it always mean millions of rows or gigabytes of data?  
  - Could a few hundred samples also be considered "huge" in some contexts?  
  - How do factors like model complexity, number of features, and task difficulty affect what "huge" means?  
  - Is "huge" an absolute term, or is it relative to the problem and model?  
